{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNdSZxX4C4nhoKqFEF1b212"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"4bc8a9e7ded7445d9a664266ec1ce1bb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e3b71375344e4b93934a6a7747999440","IPY_MODEL_ffa2db7647144f2fb73963393694db5c","IPY_MODEL_028c8f5bed5f45a1a27ed4113e08ea62"],"layout":"IPY_MODEL_56b33665cc1646d38eb7679329aa51b9"}},"e3b71375344e4b93934a6a7747999440":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_25d0eaa0658f4fe88ecf93c1035c0d77","placeholder":"​","style":"IPY_MODEL_00dd077fd8f040b583dac4a577ee195d","value":"Map: 100%"}},"ffa2db7647144f2fb73963393694db5c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4ce310ea83854350a6440e7ef4be6f6e","max":200,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3b6dd2dabb8845ed8d4333d1945835fe","value":200}},"028c8f5bed5f45a1a27ed4113e08ea62":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a06e52b74f394559b86074d6a949e2e7","placeholder":"​","style":"IPY_MODEL_b6f41106fbd44e82883ce3bf7eb3eb3f","value":" 200/200 [00:00&lt;00:00, 1229.89 examples/s]"}},"56b33665cc1646d38eb7679329aa51b9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"25d0eaa0658f4fe88ecf93c1035c0d77":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"00dd077fd8f040b583dac4a577ee195d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4ce310ea83854350a6440e7ef4be6f6e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3b6dd2dabb8845ed8d4333d1945835fe":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a06e52b74f394559b86074d6a949e2e7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b6f41106fbd44e82883ce3bf7eb3eb3f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"98d23c36e2a243fe9c96db6299ea6774":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9785189e6a5b438d86a82d12c8dbfe4a","IPY_MODEL_434efe4a4fab4483909b0c371db0e794","IPY_MODEL_1039de45b7b845b8a5c1a0894e131719"],"layout":"IPY_MODEL_3e4888dea9e24919877e7cd73ac132a3"}},"9785189e6a5b438d86a82d12c8dbfe4a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cae16172f93e4ca98679e64f72ef9153","placeholder":"​","style":"IPY_MODEL_581053f1c6574f19b66192f5dac79c49","value":"100%"}},"434efe4a4fab4483909b0c371db0e794":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1263c0e6df2441008bcbf4ceabc514df","max":10,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2c448f71df804000af3351c8e04ba08f","value":10}},"1039de45b7b845b8a5c1a0894e131719":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_97c5a9b5dbc548e6a59a04b97dfc18c6","placeholder":"​","style":"IPY_MODEL_556a3b67697a416ebe388ff3c8357f6f","value":" 10/10 [13:15&lt;00:00, 22.89s/it]"}},"3e4888dea9e24919877e7cd73ac132a3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cae16172f93e4ca98679e64f72ef9153":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"581053f1c6574f19b66192f5dac79c49":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1263c0e6df2441008bcbf4ceabc514df":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2c448f71df804000af3351c8e04ba08f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"97c5a9b5dbc548e6a59a04b97dfc18c6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"556a3b67697a416ebe388ff3c8357f6f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d3febe213b3e4d209473c44d510c00a3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e7b2ae9454c64d288f662d7c1b10bc3e","IPY_MODEL_b251d6ce32a047758113dd991b33ffa1","IPY_MODEL_8bbd702a7b0f4d36ab4c882048de5a01"],"layout":"IPY_MODEL_52629175c31c472c938a140ec62bff46"}},"e7b2ae9454c64d288f662d7c1b10bc3e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f70b14bb8aa1468296f0a1af09259c8d","placeholder":"​","style":"IPY_MODEL_08def2daf8a04f4d95f17f9ac279015d","value":"100%"}},"b251d6ce32a047758113dd991b33ffa1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6b8083f4d0154eb5b445d2408d23b2fc","max":10,"min":0,"orientation":"horizontal","style":"IPY_MODEL_39295db7549848768572fcef924c5283","value":10}},"8bbd702a7b0f4d36ab4c882048de5a01":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_250f2439811f4ea5bd2a1b958d801f85","placeholder":"​","style":"IPY_MODEL_69cea85a8617422490c234fbf0e2e51e","value":" 10/10 [08:54&lt;00:00, 22.17s/it]"}},"52629175c31c472c938a140ec62bff46":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f70b14bb8aa1468296f0a1af09259c8d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"08def2daf8a04f4d95f17f9ac279015d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6b8083f4d0154eb5b445d2408d23b2fc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"39295db7549848768572fcef924c5283":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"250f2439811f4ea5bd2a1b958d801f85":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"69cea85a8617422490c234fbf0e2e51e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"76d2bc53d9914549b3c6dae7c70d6c88":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a6f3eb3093e44bbb9dd65727ed84f784","IPY_MODEL_bcd6b2d88a3d4597a602b3beda2812f4","IPY_MODEL_bb84e790f4834fa6981472de7871898d"],"layout":"IPY_MODEL_18c3baa486a14d6d8cc4552785cc2b31"}},"a6f3eb3093e44bbb9dd65727ed84f784":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_11879c8c2f8e49479d48bd007410495e","placeholder":"​","style":"IPY_MODEL_856a3d529a824162b544ec069bb6c0d9","value":"100%"}},"bcd6b2d88a3d4597a602b3beda2812f4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0dd5490a66d049e0b23d2d82e05226f0","max":10,"min":0,"orientation":"horizontal","style":"IPY_MODEL_19e4af8193d34404a94e4cef90d05006","value":10}},"bb84e790f4834fa6981472de7871898d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_66c000007eea448183abe91b58543d38","placeholder":"​","style":"IPY_MODEL_d6f87e27daa240a991139f9563d237bf","value":" 10/10 [04:56&lt;00:00, 22.36s/it]"}},"18c3baa486a14d6d8cc4552785cc2b31":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"11879c8c2f8e49479d48bd007410495e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"856a3d529a824162b544ec069bb6c0d9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0dd5490a66d049e0b23d2d82e05226f0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"19e4af8193d34404a94e4cef90d05006":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"66c000007eea448183abe91b58543d38":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d6f87e27daa240a991139f9563d237bf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a16368a75e2040e79d89527df28b4bdf":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5884a12f59cf4747af3cf1cbec14b10e","IPY_MODEL_ce80d3ed939f44a4b9aef0e658e68964","IPY_MODEL_f082d9f74e5240aa914257fa9a5981ab"],"layout":"IPY_MODEL_13450969c4024e3c86111d9c161e4cca"}},"5884a12f59cf4747af3cf1cbec14b10e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f841c16a533b40e291543191e94946eb","placeholder":"​","style":"IPY_MODEL_d4c5c63773384cd2a39ad36cced891df","value":"100%"}},"ce80d3ed939f44a4b9aef0e658e68964":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_c9b84448bf964ea0b2b6848abcffb556","max":10,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8e55f2de41d84b75bd27c239c5ae95df","value":10}},"f082d9f74e5240aa914257fa9a5981ab":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5e828b89af1d4025aecd641ae4f6ad13","placeholder":"​","style":"IPY_MODEL_4fa03ffc43c84afbb54dbb512fc56c85","value":" 10/10 [04:12&lt;00:00, 23.02s/it]"}},"13450969c4024e3c86111d9c161e4cca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f841c16a533b40e291543191e94946eb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d4c5c63773384cd2a39ad36cced891df":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c9b84448bf964ea0b2b6848abcffb556":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8e55f2de41d84b75bd27c239c5ae95df":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5e828b89af1d4025aecd641ae4f6ad13":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4fa03ffc43c84afbb54dbb512fc56c85":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","source":["!pip install datasets"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BOZ7hXQuymzu","executionInfo":{"status":"ok","timestamp":1710236139928,"user_tz":-420,"elapsed":16746,"user":{"displayName":"Pirunrat Kaewphanoaw","userId":"16190790272292098917"}},"outputId":"30822a25-db0b-465c-d62d-8640ed20f621"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.18.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n","Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n","Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.2)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n","Requirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.3)\n","Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.20.3)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets) (4.10.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3HlFTHmptRqt","executionInfo":{"status":"ok","timestamp":1710236149830,"user_tz":-420,"elapsed":9906,"user":{"displayName":"Pirunrat Kaewphanoaw","userId":"16190790272292098917"}},"outputId":"96738e8b-a53a-4bc6-a8f7-9d777728b313"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["('2.18.0', '4.38.2', '2.1.0+cu121')"]},"metadata":{},"execution_count":2}],"source":["# !pip install datasets --upgrade\n","import datasets\n","import transformers\n","import torch\n","datasets.__version__, transformers.__version__, torch.__version__"]},{"cell_type":"code","source":["import torch.nn as nn\n","import torch\n","from tqdm.auto import tqdm\n","import random, math, time\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(device)\n","\n","#make our work comparable if restarted the kernel\n","SEED = 1234\n","torch.manual_seed(SEED)\n","torch.backends.cudnn.deterministic = True"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X5kiNQGoyt1h","executionInfo":{"status":"ok","timestamp":1710236149830,"user_tz":-420,"elapsed":4,"user":{"displayName":"Pirunrat Kaewphanoaw","userId":"16190790272292098917"}},"outputId":"adb6c230-845e-4bd4-d49f-3cb77ed9a405"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["cpu\n"]}]},{"cell_type":"markdown","source":["**1. Loading our MNLI part of the GLUE dataset**"],"metadata":{"id":"Cxtmtv2IzJu2"}},{"cell_type":"code","source":["###1. Load Dataset\n","task_to_keys = {\n","    \"cola\": (\"sentence\", None),\n","    \"mnli\": (\"premise\", \"hypothesis\"),\n","    \"mrpc\": (\"sentence1\", \"sentence2\"),\n","    \"qnli\": (\"question\", \"sentence\"),\n","    \"qqp\": (\"question1\", \"question2\"),\n","    \"rte\": (\"sentence1\", \"sentence2\"),\n","    \"sst2\": (\"sentence\", None),\n","    \"stsb\": (\"sentence1\", \"sentence2\"),\n","    \"wnli\": (\"sentence1\", \"sentence2\"),\n","}\n","\n","task_name = \"mnli\"\n","raw_datasets = datasets.load_dataset(\"glue\", task_name)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MY5a4PXMzHTi","executionInfo":{"status":"ok","timestamp":1710236153900,"user_tz":-420,"elapsed":4073,"user":{"displayName":"Pirunrat Kaewphanoaw","userId":"16190790272292098917"}},"outputId":"8e9b219a-3fe7-4387-b2c5-1aceede29896"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["raw_datasets"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eUJYamZ25zq1","executionInfo":{"status":"ok","timestamp":1710236153900,"user_tz":-420,"elapsed":6,"user":{"displayName":"Pirunrat Kaewphanoaw","userId":"16190790272292098917"}},"outputId":"0921cc13-b8f3-4b37-c73d-7513e2d2f900"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['premise', 'hypothesis', 'label', 'idx'],\n","        num_rows: 392702\n","    })\n","    validation_matched: Dataset({\n","        features: ['premise', 'hypothesis', 'label', 'idx'],\n","        num_rows: 9815\n","    })\n","    validation_mismatched: Dataset({\n","        features: ['premise', 'hypothesis', 'label', 'idx'],\n","        num_rows: 9832\n","    })\n","    test_matched: Dataset({\n","        features: ['premise', 'hypothesis', 'label', 'idx'],\n","        num_rows: 9796\n","    })\n","    test_mismatched: Dataset({\n","        features: ['premise', 'hypothesis', 'label', 'idx'],\n","        num_rows: 9847\n","    })\n","})"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["from datasets import DatasetDict\n","\n","raw_datasets = {\n","    \"train\": raw_datasets[\"train\"].select(range(200)),\n","    \"validation_matched\": raw_datasets[\"validation_matched\"].select(range(200)),\n","    \"validation_mismatched\": raw_datasets[\"validation_mismatched\"].select(range(200)),\n","    \"test_matched\": raw_datasets[\"test_matched\"].select(range(200)),\n","    \"test_mismatched\": raw_datasets[\"test_mismatched\"].select(range(200))\n","}\n","\n","raw_datasets = DatasetDict(raw_datasets)"],"metadata":{"id":"p5mGIGIn_kWe","executionInfo":{"status":"ok","timestamp":1710236153901,"user_tz":-420,"elapsed":6,"user":{"displayName":"Pirunrat Kaewphanoaw","userId":"16190790272292098917"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["label_list = raw_datasets['train'].features['label'].names\n","label2id = {v: i for i, v in enumerate(label_list)}\n","label2id"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eM37cONhzVua","executionInfo":{"status":"ok","timestamp":1710236153901,"user_tz":-420,"elapsed":6,"user":{"displayName":"Pirunrat Kaewphanoaw","userId":"16190790272292098917"}},"outputId":"d22f064d-3b60-4069-c6b7-281180f46444"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'entailment': 0, 'neutral': 1, 'contradiction': 2}"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["id2label = {i: v for v, i in label2id.items()}\n","id2label"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u0hheUF-zaIl","executionInfo":{"status":"ok","timestamp":1710236153901,"user_tz":-420,"elapsed":5,"user":{"displayName":"Pirunrat Kaewphanoaw","userId":"16190790272292098917"}},"outputId":"02ce6536-dfb4-4c53-a157-857c0c92b7b9"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{0: 'entailment', 1: 'neutral', 2: 'contradiction'}"]},"metadata":{},"execution_count":8}]},{"cell_type":"markdown","source":["**2.Model & Tokenization**"],"metadata":{"id":"Kwoms2d3zePM"}},{"cell_type":"code","source":["import numpy as np\n","num_labels = np.unique(raw_datasets['train']['label']).size\n","num_labels"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lB6rCSiTzcU7","executionInfo":{"status":"ok","timestamp":1710236153901,"user_tz":-420,"elapsed":3,"user":{"displayName":"Pirunrat Kaewphanoaw","userId":"16190790272292098917"}},"outputId":"ca3a6d4d-f91d-44af-9683-2924d3929e81"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["3"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["\n","from transformers import AutoModelForSequenceClassification\n","from transformers import AutoTokenizer\n","\n","teacher_id = \"bert-base-uncased\"\n","tokenizer = AutoTokenizer.from_pretrained(teacher_id)\n","\n","teacher_model = AutoModelForSequenceClassification.from_pretrained(\n","    teacher_id,\n","    num_labels = num_labels,\n","    id2label = id2label,\n","    label2id = label2id,\n",")\n","\n","teacher_model"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B7UjkjSyzkQ_","executionInfo":{"status":"ok","timestamp":1710236155336,"user_tz":-420,"elapsed":1437,"user":{"displayName":"Pirunrat Kaewphanoaw","userId":"16190790272292098917"}},"outputId":"e1eea830-5716-418d-9e8c-0fe0a7252a68"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"execute_result","data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",")"]},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","source":["**3. Preprocessing**"],"metadata":{"id":"IfIP59IpzrFO"}},{"cell_type":"code","source":["def tokenize_function(examples):\n","    sentence1_key, sentence2_key = task_to_keys[task_name]\n","    args = (\n","        (examples[sentence1_key],) if sentence2_key is None else (examples[sentence1_key], examples[sentence2_key])\n","    )\n","    result = tokenizer(*args, max_length=128, truncation=True)\n","    return result"],"metadata":{"id":"G3kbNn5gzmpW","executionInfo":{"status":"ok","timestamp":1710236155336,"user_tz":-420,"elapsed":5,"user":{"displayName":"Pirunrat Kaewphanoaw","userId":"16190790272292098917"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n","tokenized_datasets"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":431,"referenced_widgets":["4bc8a9e7ded7445d9a664266ec1ce1bb","e3b71375344e4b93934a6a7747999440","ffa2db7647144f2fb73963393694db5c","028c8f5bed5f45a1a27ed4113e08ea62","56b33665cc1646d38eb7679329aa51b9","25d0eaa0658f4fe88ecf93c1035c0d77","00dd077fd8f040b583dac4a577ee195d","4ce310ea83854350a6440e7ef4be6f6e","3b6dd2dabb8845ed8d4333d1945835fe","a06e52b74f394559b86074d6a949e2e7","b6f41106fbd44e82883ce3bf7eb3eb3f"]},"id":"183dkUcEzvJG","executionInfo":{"status":"ok","timestamp":1710236155671,"user_tz":-420,"elapsed":339,"user":{"displayName":"Pirunrat Kaewphanoaw","userId":"16190790272292098917"}},"outputId":"08b73352-c78c-462c-ac98-3219c539d5ad"},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/200 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4bc8a9e7ded7445d9a664266ec1ce1bb"}},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['premise', 'hypothesis', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n","        num_rows: 200\n","    })\n","    validation_matched: Dataset({\n","        features: ['premise', 'hypothesis', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n","        num_rows: 200\n","    })\n","    validation_mismatched: Dataset({\n","        features: ['premise', 'hypothesis', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n","        num_rows: 200\n","    })\n","    test_matched: Dataset({\n","        features: ['premise', 'hypothesis', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n","        num_rows: 200\n","    })\n","    test_mismatched: Dataset({\n","        features: ['premise', 'hypothesis', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n","        num_rows: 200\n","    })\n","})"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["# list(task_to_keys[task_name])\n","column_dataset = [item for item in task_to_keys[task_name] if item is not None]\n","column_dataset"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GU_rE4Ukzwa0","executionInfo":{"status":"ok","timestamp":1710236155671,"user_tz":-420,"elapsed":6,"user":{"displayName":"Pirunrat Kaewphanoaw","userId":"16190790272292098917"}},"outputId":"57673244-95ae-428d-8953-8cb9a45894d7"},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['premise', 'hypothesis']"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["#remove column : 'premise', 'hypothesis', 'idx'\n","tokenized_datasets = tokenized_datasets.remove_columns(column_dataset + [\"idx\"])\n","#rename column : 'labels'\n","tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n","tokenized_datasets.set_format(\"torch\")\n","tokenized_datasets"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dSj80gER0Ni3","executionInfo":{"status":"ok","timestamp":1710236155672,"user_tz":-420,"elapsed":6,"user":{"displayName":"Pirunrat Kaewphanoaw","userId":"16190790272292098917"}},"outputId":"44b94fec-1266-4f02-d931-f3104ceac677"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n","        num_rows: 200\n","    })\n","    validation_matched: Dataset({\n","        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n","        num_rows: 200\n","    })\n","    validation_mismatched: Dataset({\n","        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n","        num_rows: 200\n","    })\n","    test_matched: Dataset({\n","        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n","        num_rows: 200\n","    })\n","    test_mismatched: Dataset({\n","        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n","        num_rows: 200\n","    })\n","})"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["tokenized_datasets['train'][0]['input_ids'].size()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AZlEVe3y0ZX8","executionInfo":{"status":"ok","timestamp":1710236155672,"user_tz":-420,"elapsed":5,"user":{"displayName":"Pirunrat Kaewphanoaw","userId":"16190790272292098917"}},"outputId":"f666e41a-fdc8-42d8-f9e5-6c9d73e4b0fd"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([28])"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["tokenizer.decode(tokenized_datasets['train'][0]['input_ids'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"EyE0ghVs0cL0","executionInfo":{"status":"ok","timestamp":1710236155672,"user_tz":-420,"elapsed":4,"user":{"displayName":"Pirunrat Kaewphanoaw","userId":"16190790272292098917"}},"outputId":"efecaea3-dacb-4ff7-9525-0b0c162a73f9"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'[CLS] conceptually cream skimming has two basic dimensions - product and geography. [SEP] product and geography are what make cream skimming work. [SEP]'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":16}]},{"cell_type":"markdown","source":["**4. Preparing the datatloader**"],"metadata":{"id":"nniJeETK0kjV"}},{"cell_type":"code","source":["#Data collator that will dynamically pad the inputs received.\n","from transformers import DataCollatorWithPadding\n","data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"],"metadata":{"id":"lSboDWTr0dl2","executionInfo":{"status":"ok","timestamp":1710236164309,"user_tz":-420,"elapsed":8640,"user":{"displayName":"Pirunrat Kaewphanoaw","userId":"16190790272292098917"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=1150).select(range(50))\n","small_eval_dataset = tokenized_datasets[\"validation_mismatched\"].shuffle(seed=1150).select(range(10))\n","small_test_dataset = tokenized_datasets[\"test_mismatched\"].shuffle(seed=1150).select(range(10))"],"metadata":{"id":"BWMjMB740uBh","executionInfo":{"status":"ok","timestamp":1710236164310,"user_tz":-420,"elapsed":15,"user":{"displayName":"Pirunrat Kaewphanoaw","userId":"16190790272292098917"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import DataLoader\n","train_dataloader = DataLoader(\n","    small_train_dataset, shuffle=True, batch_size=32, collate_fn=data_collator)\n","test_dataloader = DataLoader(\n","    small_test_dataset, batch_size=32, collate_fn=data_collator)\n","eval_dataloader = DataLoader(\n","    small_eval_dataset, batch_size=32, collate_fn=data_collator)"],"metadata":{"id":"HDL6aQUn0z2A","executionInfo":{"status":"ok","timestamp":1710236164310,"user_tz":-420,"elapsed":14,"user":{"displayName":"Pirunrat Kaewphanoaw","userId":"16190790272292098917"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["for batch in train_dataloader:\n","    break\n","\n","batch['labels'].shape, batch['input_ids'].shape, batch['attention_mask'].shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YO65F4da02XS","executionInfo":{"status":"ok","timestamp":1710236164310,"user_tz":-420,"elapsed":14,"user":{"displayName":"Pirunrat Kaewphanoaw","userId":"16190790272292098917"}},"outputId":"340683f6-4199-4d57-e96d-d5a534d9e05a"},"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torch.Size([32]), torch.Size([32, 121]), torch.Size([32, 121]))"]},"metadata":{},"execution_count":20}]},{"cell_type":"markdown","source":["**5. Design the model and loss**"],"metadata":{"id":"FuQ3d6pt09Et"}},{"cell_type":"code","source":["teacher_model.config"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XUsi26Qp06As","executionInfo":{"status":"ok","timestamp":1710236164310,"user_tz":-420,"elapsed":13,"user":{"displayName":"Pirunrat Kaewphanoaw","userId":"16190790272292098917"}},"outputId":"05622f39-3536-4308-b1a9-954543061972"},"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["BertConfig {\n","  \"_name_or_path\": \"bert-base-uncased\",\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"entailment\",\n","    \"1\": \"neutral\",\n","    \"2\": \"contradiction\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"contradiction\": 2,\n","    \"entailment\": 0,\n","    \"neutral\": 1\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.38.2\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}"]},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":["from transformers.models.bert.modeling_bert import BertPreTrainedModel, BertConfig\n","# Get teacher configuration as a dictionnary\n","configuration = teacher_model.config.to_dict()\n","configuration"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Jg8y5b8z1rke","executionInfo":{"status":"ok","timestamp":1710236164310,"user_tz":-420,"elapsed":12,"user":{"displayName":"Pirunrat Kaewphanoaw","userId":"16190790272292098917"}},"outputId":"26fceefa-5d73-4e93-cb38-7bac95343ccb"},"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'return_dict': True,\n"," 'output_hidden_states': False,\n"," 'output_attentions': False,\n"," 'torchscript': False,\n"," 'torch_dtype': None,\n"," 'use_bfloat16': False,\n"," 'tf_legacy_loss': False,\n"," 'pruned_heads': {},\n"," 'tie_word_embeddings': True,\n"," 'chunk_size_feed_forward': 0,\n"," 'is_encoder_decoder': False,\n"," 'is_decoder': False,\n"," 'cross_attention_hidden_size': None,\n"," 'add_cross_attention': False,\n"," 'tie_encoder_decoder': False,\n"," 'max_length': 20,\n"," 'min_length': 0,\n"," 'do_sample': False,\n"," 'early_stopping': False,\n"," 'num_beams': 1,\n"," 'num_beam_groups': 1,\n"," 'diversity_penalty': 0.0,\n"," 'temperature': 1.0,\n"," 'top_k': 50,\n"," 'top_p': 1.0,\n"," 'typical_p': 1.0,\n"," 'repetition_penalty': 1.0,\n"," 'length_penalty': 1.0,\n"," 'no_repeat_ngram_size': 0,\n"," 'encoder_no_repeat_ngram_size': 0,\n"," 'bad_words_ids': None,\n"," 'num_return_sequences': 1,\n"," 'output_scores': False,\n"," 'return_dict_in_generate': False,\n"," 'forced_bos_token_id': None,\n"," 'forced_eos_token_id': None,\n"," 'remove_invalid_values': False,\n"," 'exponential_decay_length_penalty': None,\n"," 'suppress_tokens': None,\n"," 'begin_suppress_tokens': None,\n"," 'architectures': ['BertForMaskedLM'],\n"," 'finetuning_task': None,\n"," 'id2label': {0: 'entailment', 1: 'neutral', 2: 'contradiction'},\n"," 'label2id': {'entailment': 0, 'neutral': 1, 'contradiction': 2},\n"," 'tokenizer_class': None,\n"," 'prefix': None,\n"," 'bos_token_id': None,\n"," 'pad_token_id': 0,\n"," 'eos_token_id': None,\n"," 'sep_token_id': None,\n"," 'decoder_start_token_id': None,\n"," 'task_specific_params': None,\n"," 'problem_type': None,\n"," '_name_or_path': 'bert-base-uncased',\n"," 'transformers_version': '4.38.2',\n"," 'gradient_checkpointing': False,\n"," 'model_type': 'bert',\n"," 'vocab_size': 30522,\n"," 'hidden_size': 768,\n"," 'num_hidden_layers': 12,\n"," 'num_attention_heads': 12,\n"," 'hidden_act': 'gelu',\n"," 'intermediate_size': 3072,\n"," 'hidden_dropout_prob': 0.1,\n"," 'attention_probs_dropout_prob': 0.1,\n"," 'max_position_embeddings': 512,\n"," 'type_vocab_size': 2,\n"," 'initializer_range': 0.02,\n"," 'layer_norm_eps': 1e-12,\n"," 'position_embedding_type': 'absolute',\n"," 'use_cache': True,\n"," 'classifier_dropout': None}"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["from transformers.models.bert.modeling_bert import BertEncoder, BertModel\n","from torch.nn import Module\n","\n","def distill_bert_weights(\n","    teacher : Module,\n","    student : Module,\n",") -> None:\n","    \"\"\"\n","    Recursively copies the weights of the (teacher) to the (student).\n","    This function is meant to be first called on a BertFor... model, but is then called on every children of that model recursively.\n","    The only part that's not fully copied is the encoder, of which only half is copied.\n","    \"\"\"\n","    # If the part is an entire BERT model or a BERTFor..., unpack and iterate\n","    if isinstance(teacher, BertModel) or type(teacher).__name__.startswith('BertFor'):\n","        for teacher_part, student_part in zip(teacher.children(), student.children()):\n","            distill_bert_weights(teacher_part, student_part)\n","    # Else if the part is an encoder, copy one out of every layer\n","    elif isinstance(teacher, BertEncoder):\n","        teacher_encoding_layers = [layer for layer in next(teacher.children())] #12 layers\n","        student_encoding_layers = [layer for layer in next(student.children())] #6 layers\n","        for i in range(len(student_encoding_layers)):\n","            student_encoding_layers[i].load_state_dict(teacher_encoding_layers[2*i].state_dict())\n","    # Else the part is a head or something else, copy the state_dict\n","    else:\n","        student.load_state_dict(teacher.state_dict())\n","\n","    return model1"],"metadata":{"id":"yYA56Ozd72K4","executionInfo":{"status":"ok","timestamp":1710236164820,"user_tz":-420,"elapsed":520,"user":{"displayName":"Pirunrat Kaewphanoaw","userId":"16190790272292098917"}}},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":["**Top K layers {1,2,3,4,5,6}**"],"metadata":{"id":"5QR8XE3P2BTm"}},{"cell_type":"code","source":["# Half the number of hidden layer\n","configuration['num_hidden_layers'] //= 2\n","# Convert the dictionnary to the student configuration\n","configuration = BertConfig.from_dict(configuration)"],"metadata":{"id":"dNtglGJA19-Y","executionInfo":{"status":"ok","timestamp":1710236164820,"user_tz":-420,"elapsed":1,"user":{"displayName":"Pirunrat Kaewphanoaw","userId":"16190790272292098917"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["# Create uninitialized student model\n","model1 = type(teacher_model)(configuration)\n","model1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"laA5ZbNt2Uzj","executionInfo":{"status":"ok","timestamp":1710236167682,"user_tz":-420,"elapsed":2863,"user":{"displayName":"Pirunrat Kaewphanoaw","userId":"16190790272292098917"}},"outputId":"a1f7c616-60e9-400c-c17b-6f71cc243fe0"},"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0-5): 6 x BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",")"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["model1 = distill_bert_weights(teacher=teacher_model, student=model1)"],"metadata":{"id":"3uvDZo6076Tg","executionInfo":{"status":"ok","timestamp":1710236167683,"user_tz":-420,"elapsed":12,"user":{"displayName":"Pirunrat Kaewphanoaw","userId":"16190790272292098917"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["def count_parameters(model):\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","print('Teacher parameters :', count_parameters(teacher_model))\n","print('Student parameters :', count_parameters(model1))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C7420qAd7_7-","executionInfo":{"status":"ok","timestamp":1710236167683,"user_tz":-420,"elapsed":12,"user":{"displayName":"Pirunrat Kaewphanoaw","userId":"16190790272292098917"}},"outputId":"4f6aed4b-cfa6-419b-a15b-29469348bd8c"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["Teacher parameters : 109484547\n","Student parameters : 66957315\n"]}]},{"cell_type":"code","source":["count_parameters(model1)/count_parameters(teacher_model) * 100"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xGN8pFY-8Jy-","executionInfo":{"status":"ok","timestamp":1710236167683,"user_tz":-420,"elapsed":11,"user":{"displayName":"Pirunrat Kaewphanoaw","userId":"16190790272292098917"}},"outputId":"11bd2d66-afe3-4d78-fb6e-5223f664123f"},"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/plain":["61.15686353435797"]},"metadata":{},"execution_count":28}]},{"cell_type":"markdown","source":["**Bottom K layers {7,8,9,10,11,12}**"],"metadata":{"id":"UaHXsnzm43uT"}},{"cell_type":"code","source":["# Create uninitialized student model\n","model2 = type(teacher_model)(configuration)\n","model2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x4NHi1414t8h","executionInfo":{"status":"ok","timestamp":1710236170629,"user_tz":-420,"elapsed":2956,"user":{"displayName":"Pirunrat Kaewphanoaw","userId":"16190790272292098917"}},"outputId":"2838a2c3-8275-4456-f4a6-44b56b93657f"},"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0-5): 6 x BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",")"]},"metadata":{},"execution_count":29}]},{"cell_type":"code","source":["def distill_bert_weights_bottom(\n","    teacher: Module,\n","    student: Module,\n","    bottom_layers: list = [7, 8, 9, 10, 11, 12]\n",") -> None:\n","    \"\"\"\n","    Recursively copies the weights of the (teacher) to the (student) for specified bottom layers.\n","    \"\"\"\n","    # If the part is an entire BERT model or a BERTFor..., unpack and iterate\n","    if isinstance(teacher, BertModel) or type(teacher).__name__.startswith('BertFor'):\n","        for teacher_part, student_part in zip(teacher.children(), student.children()):\n","            distill_bert_weights_bottom(teacher_part, student_part, bottom_layers)\n","    # Else if the part is an encoder, copy specified bottom layers\n","    elif isinstance(teacher, BertEncoder):\n","        teacher_encoding_layers = [layer for layer in next(teacher.children())]  # 12 layers\n","        student_encoding_layers = [layer for layer in next(student.children())]  # 6 layers\n","        for i, layer_num in enumerate(bottom_layers):\n","            student_encoding_layers[i].load_state_dict(teacher_encoding_layers[layer_num - 1].state_dict())\n","    # Else the part is a head or something else, copy the state_dict\n","    else:\n","        student.load_state_dict(teacher.state_dict())\n","\n","    return student"],"metadata":{"id":"vzSlZAid8RlR","executionInfo":{"status":"ok","timestamp":1710236170630,"user_tz":-420,"elapsed":3,"user":{"displayName":"Pirunrat Kaewphanoaw","userId":"16190790272292098917"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["model2 = distill_bert_weights(teacher=teacher_model, student=model2)"],"metadata":{"id":"LJ2isdWN8z3r","executionInfo":{"status":"ok","timestamp":1710236171222,"user_tz":-420,"elapsed":594,"user":{"displayName":"Pirunrat Kaewphanoaw","userId":"16190790272292098917"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["print('Teacher parameters :', count_parameters(teacher_model))\n","print('Student parameters :', count_parameters(model2))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-shuVL12846M","executionInfo":{"status":"ok","timestamp":1710236171223,"user_tz":-420,"elapsed":4,"user":{"displayName":"Pirunrat Kaewphanoaw","userId":"16190790272292098917"}},"outputId":"d75edaaa-259e-4b74-b0fe-464755f678ad"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["Teacher parameters : 109484547\n","Student parameters : 66957315\n"]}]},{"cell_type":"code","source":["count_parameters(model2)/count_parameters(teacher_model) * 100"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"en0_IdrU9e5s","executionInfo":{"status":"ok","timestamp":1710236171223,"user_tz":-420,"elapsed":3,"user":{"displayName":"Pirunrat Kaewphanoaw","userId":"16190790272292098917"}},"outputId":"93cff07b-9f1b-4f2d-8ba2-369f6e1f6ea1"},"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"text/plain":["61.15686353435797"]},"metadata":{},"execution_count":33}]},{"cell_type":"markdown","source":["**Odd layers {1,3,5,7,9,11}**"],"metadata":{"id":"okQVZCJh-ldo"}},{"cell_type":"code","source":["# Create uninitialized student model\n","model3 = type(teacher_model)(configuration)\n","model3"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ejg8NjPe--Zq","executionInfo":{"status":"ok","timestamp":1710236177187,"user_tz":-420,"elapsed":5588,"user":{"displayName":"Pirunrat Kaewphanoaw","userId":"16190790272292098917"}},"outputId":"883a5e1e-a77b-4357-b0c6-d0553d828068"},"execution_count":34,"outputs":[{"output_type":"execute_result","data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0-5): 6 x BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",")"]},"metadata":{},"execution_count":34}]},{"cell_type":"code","source":["def distill_bert_weights_odd(\n","    teacher: Module,\n","    student: Module,\n","    bottom_layers: list = [1, 3, 5, 7, 9, 11]\n",") -> None:\n","    \"\"\"\n","    Recursively copies the weights of the (teacher) to the (student) for specified bottom layers.\n","    \"\"\"\n","    # If the part is an entire BERT model or a BERTFor..., unpack and iterate\n","    if isinstance(teacher, BertModel) or type(teacher).__name__.startswith('BertFor'):\n","        for teacher_part, student_part in zip(teacher.children(), student.children()):\n","            distill_bert_weights_bottom(teacher_part, student_part, bottom_layers)\n","    # Else if the part is an encoder, copy specified bottom layers\n","    elif isinstance(teacher, BertEncoder):\n","        teacher_encoding_layers = [layer for layer in next(teacher.children())]  # 12 layers\n","        student_encoding_layers = [layer for layer in next(student.children())]  # 6 layers\n","        for i, layer_num in enumerate(bottom_layers):\n","            student_encoding_layers[i].load_state_dict(teacher_encoding_layers[layer_num - 1].state_dict())\n","    # Else the part is a head or something else, copy the state_dict\n","    else:\n","        student.load_state_dict(teacher.state_dict())\n","\n","    return student"],"metadata":{"id":"ZT3G4O9W_FTL","executionInfo":{"status":"ok","timestamp":1710236177187,"user_tz":-420,"elapsed":10,"user":{"displayName":"Pirunrat Kaewphanoaw","userId":"16190790272292098917"}}},"execution_count":35,"outputs":[]},{"cell_type":"code","source":["model3 = distill_bert_weights(teacher=teacher_model, student=model3)"],"metadata":{"id":"NfJXxzJ6_SpC","executionInfo":{"status":"ok","timestamp":1710236177187,"user_tz":-420,"elapsed":10,"user":{"displayName":"Pirunrat Kaewphanoaw","userId":"16190790272292098917"}}},"execution_count":36,"outputs":[]},{"cell_type":"code","source":["print('Teacher parameters :', count_parameters(teacher_model))\n","print('Student parameters :', count_parameters(model3))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iIdGxlVp_XFC","executionInfo":{"status":"ok","timestamp":1710236177697,"user_tz":-420,"elapsed":3,"user":{"displayName":"Pirunrat Kaewphanoaw","userId":"16190790272292098917"}},"outputId":"d8c2c1bc-22e6-4e0c-e908-a324dd8c041e"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["Teacher parameters : 109484547\n","Student parameters : 66957315\n"]}]},{"cell_type":"code","source":["count_parameters(model3)/count_parameters(teacher_model) * 100"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Pe5Q0gzu_bop","executionInfo":{"status":"ok","timestamp":1710236177697,"user_tz":-420,"elapsed":3,"user":{"displayName":"Pirunrat Kaewphanoaw","userId":"16190790272292098917"}},"outputId":"48e703f7-f62a-413a-d478-690bc0e17c6a"},"execution_count":38,"outputs":[{"output_type":"execute_result","data":{"text/plain":["61.15686353435797"]},"metadata":{},"execution_count":38}]},{"cell_type":"markdown","source":["**Even Layer {2,4,6,8,10}**"],"metadata":{"id":"gevT-U3EzWh0"}},{"cell_type":"code","source":["# Create uninitialized student model\n","model4 = type(teacher_model)(configuration)\n","model4"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5pOwtiDxzimb","executionInfo":{"status":"ok","timestamp":1710236182744,"user_tz":-420,"elapsed":5048,"user":{"displayName":"Pirunrat Kaewphanoaw","userId":"16190790272292098917"}},"outputId":"42d80075-154e-4e9e-d7c4-80f432a2b653"},"execution_count":39,"outputs":[{"output_type":"execute_result","data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0-5): 6 x BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",")"]},"metadata":{},"execution_count":39}]},{"cell_type":"code","source":["def distill_bert_weights_even(\n","    teacher: Module,\n","    student: Module,\n","    bottom_layers: list = [2,4,6,8,10,12]\n",") -> None:\n","    \"\"\"\n","    Recursively copies the weights of the (teacher) to the (student) for specified bottom layers.\n","    \"\"\"\n","    # If the part is an entire BERT model or a BERTFor..., unpack and iterate\n","    if isinstance(teacher, BertModel) or type(teacher).__name__.startswith('BertFor'):\n","        for teacher_part, student_part in zip(teacher.children(), student.children()):\n","            distill_bert_weights_bottom(teacher_part, student_part, bottom_layers)\n","    # Else if the part is an encoder, copy specified bottom layers\n","    elif isinstance(teacher, BertEncoder):\n","        teacher_encoding_layers = [layer for layer in next(teacher.children())]  # 12 layers\n","        student_encoding_layers = [layer for layer in next(student.children())]  # 6 layers\n","        for i, layer_num in enumerate(bottom_layers):\n","            student_encoding_layers[i].load_state_dict(teacher_encoding_layers[layer_num - 1].state_dict())\n","    # Else the part is a head or something else, copy the state_dict\n","    else:\n","        student.load_state_dict(teacher.state_dict())\n","\n","    return student"],"metadata":{"id":"mz3sGwz92G0-","executionInfo":{"status":"ok","timestamp":1710236182744,"user_tz":-420,"elapsed":5,"user":{"displayName":"Pirunrat Kaewphanoaw","userId":"16190790272292098917"}}},"execution_count":40,"outputs":[]},{"cell_type":"code","source":["model4 = distill_bert_weights(teacher=teacher_model, student=model4)"],"metadata":{"id":"wimnEz9T2Sou","executionInfo":{"status":"ok","timestamp":1710236182744,"user_tz":-420,"elapsed":4,"user":{"displayName":"Pirunrat Kaewphanoaw","userId":"16190790272292098917"}}},"execution_count":41,"outputs":[]},{"cell_type":"code","source":["print('Teacher parameters :', count_parameters(teacher_model))\n","print('Student parameters :', count_parameters(model4))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SVDMQUNS2ahG","executionInfo":{"status":"ok","timestamp":1710236182744,"user_tz":-420,"elapsed":3,"user":{"displayName":"Pirunrat Kaewphanoaw","userId":"16190790272292098917"}},"outputId":"5cc84f6b-c83d-4e31-a9e9-54116756f0db"},"execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":["Teacher parameters : 109484547\n","Student parameters : 66957315\n"]}]},{"cell_type":"code","source":["count_parameters(model4)/count_parameters(teacher_model) * 100"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"shHD0wf32fS-","executionInfo":{"status":"ok","timestamp":1710236182745,"user_tz":-420,"elapsed":4,"user":{"displayName":"Pirunrat Kaewphanoaw","userId":"16190790272292098917"}},"outputId":"170b845e-6c52-4c33-80ae-1ef8cc0ab523"},"execution_count":43,"outputs":[{"output_type":"execute_result","data":{"text/plain":["61.15686353435797"]},"metadata":{},"execution_count":43}]},{"cell_type":"markdown","source":["**Loss function**"],"metadata":{"id":"NNIsro6q5grp"}},{"cell_type":"code","source":["import torch.nn.functional as F\n","\n","class DistillKL(nn.Module):\n","    \"\"\"\n","    Distilling the Knowledge in a Neural Network\n","    Compute the knowledge-distillation (KD) loss given outputs, labels.\n","    \"Hyperparameters\": temperature and alpha\n","\n","    NOTE: the KL Divergence for PyTorch comparing the softmaxs of teacher\n","    and student expects the input tensor to be log probabilities!\n","    \"\"\"\n","\n","    def __init__(self):\n","        super(DistillKL, self).__init__()\n","\n","    def forward(self, output_student, output_teacher, temperature=1):\n","        '''\n","        Note: the output_student and output_teacher are logits\n","        '''\n","        T = temperature #.cuda()\n","\n","        KD_loss = nn.KLDivLoss(reduction='batchmean')(\n","            F.log_softmax(output_student/T, dim=-1),\n","            F.softmax(output_teacher/T, dim=-1)\n","        ) * T * T\n","\n","        return KD_loss"],"metadata":{"id":"NfjBB7sD2jX-","executionInfo":{"status":"ok","timestamp":1710236182745,"user_tz":-420,"elapsed":3,"user":{"displayName":"Pirunrat Kaewphanoaw","userId":"16190790272292098917"}}},"execution_count":44,"outputs":[]},{"cell_type":"code","source":["criterion_div = DistillKL()\n","criterion_cos = nn.CosineEmbeddingLoss()"],"metadata":{"id":"ZU0A_D8f5la-","executionInfo":{"status":"ok","timestamp":1710236182746,"user_tz":-420,"elapsed":4,"user":{"displayName":"Pirunrat Kaewphanoaw","userId":"16190790272292098917"}}},"execution_count":45,"outputs":[]},{"cell_type":"markdown","source":["**Optimzer**"],"metadata":{"id":"2Y4Bb3RC5opo"}},{"cell_type":"markdown","source":["1.Top-k-Model"],"metadata":{"id":"yrpaMCCG5wGQ"}},{"cell_type":"code","source":["import torch.optim as optim\n","import torch.nn as nn\n","\n","lr = 5e-5\n","\n","#training hyperparameters\n","optimizer1 = optim.Adam(params=model1.parameters(), lr=lr)"],"metadata":{"id":"OuTRhYcN5nUX","executionInfo":{"status":"ok","timestamp":1710236183984,"user_tz":-420,"elapsed":1242,"user":{"displayName":"Pirunrat Kaewphanoaw","userId":"16190790272292098917"}}},"execution_count":46,"outputs":[]},{"cell_type":"markdown","source":["2.Bottom-k-Model"],"metadata":{"id":"AopyoqN75_Kh"}},{"cell_type":"code","source":["lr = 5e-5\n","\n","#training hyperparameters\n","optimizer2 = optim.Adam(params=model2.parameters(), lr=lr)"],"metadata":{"id":"6sFH3K8n5s0n","executionInfo":{"status":"ok","timestamp":1710236183985,"user_tz":-420,"elapsed":5,"user":{"displayName":"Pirunrat Kaewphanoaw","userId":"16190790272292098917"}}},"execution_count":47,"outputs":[]},{"cell_type":"markdown","source":["3.Odd"],"metadata":{"id":"Yr-CQcIn6FsP"}},{"cell_type":"code","source":["lr = 5e-5\n","\n","#training hyperparameters\n","optimizer3 = optim.Adam(params=model3.parameters(), lr=lr)"],"metadata":{"id":"NBBFkXN86EX2","executionInfo":{"status":"ok","timestamp":1710236183985,"user_tz":-420,"elapsed":4,"user":{"displayName":"Pirunrat Kaewphanoaw","userId":"16190790272292098917"}}},"execution_count":48,"outputs":[]},{"cell_type":"markdown","source":["4.Even"],"metadata":{"id":"svmHsFLT6Lmv"}},{"cell_type":"code","source":["lr = 5e-5\n","\n","#training hyperparameters\n","optimizer4 = optim.Adam(params=model4.parameters(), lr=lr)"],"metadata":{"id":"DEBrNvAm6K2m","executionInfo":{"status":"ok","timestamp":1710236183985,"user_tz":-420,"elapsed":4,"user":{"displayName":"Pirunrat Kaewphanoaw","userId":"16190790272292098917"}}},"execution_count":49,"outputs":[]},{"cell_type":"markdown","source":["**Learning rate scheduler**"],"metadata":{"id":"iiBiBSz66p6w"}},{"cell_type":"markdown","source":["1.Top-k"],"metadata":{"id":"LOUUihVA6xOQ"}},{"cell_type":"code","source":["from transformers import get_scheduler\n","\n","num_epochs = 5\n","num_update_steps_per_epoch = len(train_dataloader)\n","num_training_steps = num_epochs * num_update_steps_per_epoch\n","\n","lr_scheduler1 = get_scheduler(\n","    name=\"linear\",\n","    optimizer=optimizer1,\n","    num_warmup_steps=0,\n","    num_training_steps=num_training_steps\n",")"],"metadata":{"id":"0sYpnBOD6PXW","executionInfo":{"status":"ok","timestamp":1710236183985,"user_tz":-420,"elapsed":4,"user":{"displayName":"Pirunrat Kaewphanoaw","userId":"16190790272292098917"}}},"execution_count":50,"outputs":[]},{"cell_type":"markdown","source":["2.Bottom-k"],"metadata":{"id":"WDOEq3Fo679Q"}},{"cell_type":"code","source":["lr_scheduler2 = get_scheduler(\n","    name=\"linear\",\n","    optimizer=optimizer2,\n","    num_warmup_steps=0,\n","    num_training_steps=num_training_steps\n",")"],"metadata":{"id":"SiwBTnU766qG","executionInfo":{"status":"ok","timestamp":1710236183985,"user_tz":-420,"elapsed":3,"user":{"displayName":"Pirunrat Kaewphanoaw","userId":"16190790272292098917"}}},"execution_count":51,"outputs":[]},{"cell_type":"markdown","source":["3.Odd"],"metadata":{"id":"TDQOHk-a7DX4"}},{"cell_type":"code","source":["lr_scheduler3 = get_scheduler(\n","    name=\"linear\",\n","    optimizer=optimizer3,\n","    num_warmup_steps=0,\n","    num_training_steps=num_training_steps\n",")"],"metadata":{"id":"gk8Nqi7S7BfH","executionInfo":{"status":"ok","timestamp":1710236183986,"user_tz":-420,"elapsed":4,"user":{"displayName":"Pirunrat Kaewphanoaw","userId":"16190790272292098917"}}},"execution_count":52,"outputs":[]},{"cell_type":"markdown","source":["4.Even"],"metadata":{"id":"6529GriE7IGA"}},{"cell_type":"code","source":["lr_scheduler4 = get_scheduler(\n","    name=\"linear\",\n","    optimizer=optimizer4,\n","    num_warmup_steps=0,\n","    num_training_steps=num_training_steps\n",")"],"metadata":{"id":"3veMVA6V7HWP","executionInfo":{"status":"ok","timestamp":1710236183986,"user_tz":-420,"elapsed":4,"user":{"displayName":"Pirunrat Kaewphanoaw","userId":"16190790272292098917"}}},"execution_count":53,"outputs":[]},{"cell_type":"markdown","source":["**Metric**"],"metadata":{"id":"EE-5Uu1Cz3zk"}},{"cell_type":"code","source":["!pip3 install evaluate"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CZThD6H10ATD","executionInfo":{"status":"ok","timestamp":1710236200508,"user_tz":-420,"elapsed":16526,"user":{"displayName":"Pirunrat Kaewphanoaw","userId":"16190790272292098917"}},"outputId":"681525c1-1425-4132-a002-43b2aa6e461b"},"execution_count":54,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.1)\n","Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.18.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.25.2)\n","Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.5.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.31.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.2)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.4.1)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\n","Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2023.6.0)\n","Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.20.3)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (23.2)\n","Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.18.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.13.1)\n","Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (14.0.2)\n","Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (0.6)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.9.3)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.10.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.2.2)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2023.4)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.16.0)\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import evaluate\n","\n","if task_name is not None:\n","    metric = evaluate.load(\"glue\", task_name)\n","else:\n","    metric = evaluate.load(\"accuracy\")"],"metadata":{"id":"wUHpdwWc7MA_","executionInfo":{"status":"ok","timestamp":1710236203564,"user_tz":-420,"elapsed":3059,"user":{"displayName":"Pirunrat Kaewphanoaw","userId":"16190790272292098917"}}},"execution_count":55,"outputs":[]},{"cell_type":"markdown","source":["**Train**"],"metadata":{"id":"0RbeI4eH0LXq"}},{"cell_type":"markdown","source":["1. Top k"],"metadata":{"id":"CzvZXZ0U0Qwi"}},{"cell_type":"code","source":["import torch\n","from tqdm.auto import tqdm\n","\n","progress_bar = tqdm(range(num_training_steps))\n","eval_metrics = 0\n","\n","# Lists to store losses for each epoch\n","train_losses = []\n","train_losses_cls = []\n","train_losses_div = []\n","train_losses_cos = []\n","eval_losses = []\n","\n","for epoch in range(num_epochs):\n","    model1.train()\n","    teacher_model.eval()\n","    train_loss = 0\n","    train_loss_cls = 0\n","    train_loss_div = 0\n","    train_loss_cos = 0\n","\n","    for batch in train_dataloader:\n","        batch = {k: v.to(device) for k, v in batch.items()}\n","        # compute student output\n","        outputs = model1(**batch)\n","        # compute teacher output\n","        with torch.no_grad():\n","            output_teacher = teacher_model(**batch)\n","\n","        # assert size\n","        assert outputs.logits.size() == output_teacher.logits.size()\n","\n","        # cls loss\n","        loss_cls  = outputs.loss\n","        train_loss_cls += loss_cls.item()\n","        # distillation loss\n","        loss_div = criterion_div(outputs.logits, output_teacher.logits)\n","        train_loss_div += loss_div.item()\n","        # cosine loss\n","        loss_cos = criterion_cos(output_teacher.logits, outputs.logits, torch.ones(output_teacher.logits.size()[0]).to(device))\n","        train_loss_cos += loss_cos.item()\n","\n","        # Average the loss and return it\n","        loss = (loss_cls + loss_div + loss_cos) / 3\n","\n","        train_loss += loss.item()\n","        loss.backward()\n","        # accelerator.backward(loss)\n","        # Step with optimizer\n","        optimizer1.step()\n","        lr_scheduler1.step()\n","        optimizer1.zero_grad()\n","        progress_bar.update(1)\n","\n","    train_losses.append(train_loss / len(train_dataloader))\n","    train_losses_cls.append(train_loss_cls / len(train_dataloader))\n","    train_losses_div.append(train_loss_div / len(train_dataloader))\n","    train_losses_cos.append(train_loss_cos / len(train_dataloader))\n","\n","    print(f'Epoch at {epoch+1}: Train loss {train_loss/len(train_dataloader):.4f}:')\n","    print(f'  - Loss_cls: {train_loss_cls/len(train_dataloader):.4f}')\n","    print(f'  - Loss_div: {train_loss_div/len(train_dataloader):.4f}')\n","    print(f'  - Loss_cos: {train_loss_cos/len(train_dataloader):.4f}')\n","\n","    model1.eval()\n","    eval_loss = 0\n","    for batch in eval_dataloader:\n","        batch = {k: v.to(device) for k, v in batch.items()}\n","        with torch.no_grad():\n","            outputs = model1(**batch)\n","\n","        loss_cls = outputs.loss\n","        predictions = outputs.logits.argmax(dim=-1)\n","\n","        eval_loss += loss_cls.item()\n","        # predictions, references = accelerator.gather((predictions, batch[\"labels\"]))\n","        metric.add_batch(\n","            predictions=predictions,\n","            references=batch[\"labels\"])\n","\n","    eval_metric = metric.compute()\n","    eval_metrics += eval_metric['accuracy']\n","    eval_losses.append(eval_loss / len(eval_dataloader))  # Save the evaluation loss for plotting\n","\n","    print(f\"Epoch at {epoch+1}: Test Acc {eval_metric['accuracy']:.4f}\")\n","\n","print('Avg Metric', eval_metrics/num_epochs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":500,"referenced_widgets":["98d23c36e2a243fe9c96db6299ea6774","9785189e6a5b438d86a82d12c8dbfe4a","434efe4a4fab4483909b0c371db0e794","1039de45b7b845b8a5c1a0894e131719","3e4888dea9e24919877e7cd73ac132a3","cae16172f93e4ca98679e64f72ef9153","581053f1c6574f19b66192f5dac79c49","1263c0e6df2441008bcbf4ceabc514df","2c448f71df804000af3351c8e04ba08f","97c5a9b5dbc548e6a59a04b97dfc18c6","556a3b67697a416ebe388ff3c8357f6f"]},"id":"KfbkWqD9z7vR","executionInfo":{"status":"ok","timestamp":1710236464109,"user_tz":-420,"elapsed":260548,"user":{"displayName":"Pirunrat Kaewphanoaw","userId":"16190790272292098917"}},"outputId":"aa159cef-3785-4b44-a86e-e947e49e3de4"},"execution_count":56,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/10 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"98d23c36e2a243fe9c96db6299ea6774"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch at 1: Train loss 0.6066:\n","  - Loss_cls: 1.1035\n","  - Loss_div: 0.0388\n","  - Loss_cos: 0.6776\n","Epoch at 1: Test Acc 0.4000\n","Epoch at 2: Train loss 0.3777:\n","  - Loss_cls: 1.0668\n","  - Loss_div: 0.0097\n","  - Loss_cos: 0.0567\n","Epoch at 2: Test Acc 0.2000\n","Epoch at 3: Train loss 0.3803:\n","  - Loss_cls: 1.0610\n","  - Loss_div: 0.0126\n","  - Loss_cos: 0.0673\n","Epoch at 3: Test Acc 0.2000\n","Epoch at 4: Train loss 0.3726:\n","  - Loss_cls: 1.0450\n","  - Loss_div: 0.0175\n","  - Loss_cos: 0.0551\n","Epoch at 4: Test Acc 0.3000\n","Epoch at 5: Train loss 0.3698:\n","  - Loss_cls: 1.0342\n","  - Loss_div: 0.0125\n","  - Loss_cos: 0.0629\n","Epoch at 5: Test Acc 0.3000\n","Avg Metric 0.28\n"]}]},{"cell_type":"markdown","source":["2.Bottom-K"],"metadata":{"id":"0BTSGcRfDmD3"}},{"cell_type":"code","source":["import torch\n","from tqdm.auto import tqdm\n","\n","progress_bar = tqdm(range(num_training_steps))\n","eval_metrics = 0\n","\n","# Lists to store losses for each epoch\n","train_losses = []\n","train_losses_cls = []\n","train_losses_div = []\n","train_losses_cos = []\n","eval_losses = []\n","\n","for epoch in range(num_epochs):\n","    model2.train()\n","    teacher_model.eval()\n","    train_loss = 0\n","    train_loss_cls = 0\n","    train_loss_div = 0\n","    train_loss_cos = 0\n","\n","    for batch in train_dataloader:\n","        batch = {k: v.to(device) for k, v in batch.items()}\n","        # compute student output\n","        outputs = model2(**batch)\n","        # compute teacher output\n","        with torch.no_grad():\n","            output_teacher = teacher_model(**batch)\n","\n","        # assert size\n","        assert outputs.logits.size() == output_teacher.logits.size()\n","\n","        # cls loss\n","        loss_cls  = outputs.loss\n","        train_loss_cls += loss_cls.item()\n","        # distillation loss\n","        loss_div = criterion_div(outputs.logits, output_teacher.logits)\n","        train_loss_div += loss_div.item()\n","        # cosine loss\n","        loss_cos = criterion_cos(output_teacher.logits, outputs.logits, torch.ones(output_teacher.logits.size()[0]).to(device))\n","        train_loss_cos += loss_cos.item()\n","\n","        # Average the loss and return it\n","        loss = (loss_cls + loss_div + loss_cos) / 3\n","\n","        train_loss += loss.item()\n","        loss.backward()\n","        # accelerator.backward(loss)\n","        # Step with optimizer\n","        optimizer2.step()\n","        lr_scheduler2.step()\n","        optimizer2.zero_grad()\n","        progress_bar.update(1)\n","\n","    train_losses.append(train_loss / len(train_dataloader))\n","    train_losses_cls.append(train_loss_cls / len(train_dataloader))\n","    train_losses_div.append(train_loss_div / len(train_dataloader))\n","    train_losses_cos.append(train_loss_cos / len(train_dataloader))\n","\n","    print(f'Epoch at {epoch+1}: Train loss {train_loss/len(train_dataloader):.4f}:')\n","    print(f'  - Loss_cls: {train_loss_cls/len(train_dataloader):.4f}')\n","    print(f'  - Loss_div: {train_loss_div/len(train_dataloader):.4f}')\n","    print(f'  - Loss_cos: {train_loss_cos/len(train_dataloader):.4f}')\n","\n","    model2.eval()\n","    eval_loss = 0\n","    for batch in eval_dataloader:\n","        batch = {k: v.to(device) for k, v in batch.items()}\n","        with torch.no_grad():\n","            outputs = model2(**batch)\n","\n","        loss_cls = outputs.loss\n","        predictions = outputs.logits.argmax(dim=-1)\n","\n","        eval_loss += loss_cls.item()\n","        # predictions, references = accelerator.gather((predictions, batch[\"labels\"]))\n","        metric.add_batch(\n","            predictions=predictions,\n","            references=batch[\"labels\"])\n","\n","    eval_metric = metric.compute()\n","    eval_metrics += eval_metric['accuracy']\n","    eval_losses.append(eval_loss / len(eval_dataloader))  # Save the evaluation loss for plotting\n","\n","    print(f\"Epoch at {epoch+1}: Test Acc {eval_metric['accuracy']:.4f}\")\n","\n","print('Avg Metric', eval_metrics/num_epochs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":500,"referenced_widgets":["d3febe213b3e4d209473c44d510c00a3","e7b2ae9454c64d288f662d7c1b10bc3e","b251d6ce32a047758113dd991b33ffa1","8bbd702a7b0f4d36ab4c882048de5a01","52629175c31c472c938a140ec62bff46","f70b14bb8aa1468296f0a1af09259c8d","08def2daf8a04f4d95f17f9ac279015d","6b8083f4d0154eb5b445d2408d23b2fc","39295db7549848768572fcef924c5283","250f2439811f4ea5bd2a1b958d801f85","69cea85a8617422490c234fbf0e2e51e"]},"id":"po3-PNBDDphZ","executionInfo":{"status":"ok","timestamp":1710236702363,"user_tz":-420,"elapsed":238259,"user":{"displayName":"Pirunrat Kaewphanoaw","userId":"16190790272292098917"}},"outputId":"2ef15c2d-4537-4138-cb64-1266f128530c"},"execution_count":57,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/10 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d3febe213b3e4d209473c44d510c00a3"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch at 1: Train loss 0.3724:\n","  - Loss_cls: 1.0590\n","  - Loss_div: 0.0130\n","  - Loss_cos: 0.0452\n","Epoch at 1: Test Acc 0.4000\n","Epoch at 2: Train loss 0.3650:\n","  - Loss_cls: 0.9973\n","  - Loss_div: 0.0271\n","  - Loss_cos: 0.0706\n","Epoch at 2: Test Acc 0.4000\n","Epoch at 3: Train loss 0.3269:\n","  - Loss_cls: 0.9111\n","  - Loss_div: 0.0231\n","  - Loss_cos: 0.0464\n","Epoch at 3: Test Acc 0.2000\n","Epoch at 4: Train loss 0.3160:\n","  - Loss_cls: 0.8732\n","  - Loss_div: 0.0253\n","  - Loss_cos: 0.0494\n","Epoch at 4: Test Acc 0.2000\n","Epoch at 5: Train loss 0.3150:\n","  - Loss_cls: 0.8792\n","  - Loss_div: 0.0298\n","  - Loss_cos: 0.0361\n","Epoch at 5: Test Acc 0.3000\n","Avg Metric 0.3\n"]}]},{"cell_type":"markdown","source":["3.Odd"],"metadata":{"id":"7g-0KfruFT7_"}},{"cell_type":"code","source":["import torch\n","from tqdm.auto import tqdm\n","\n","progress_bar = tqdm(range(num_training_steps))\n","eval_metrics = 0\n","\n","# Lists to store losses for each epoch\n","train_losses = []\n","train_losses_cls = []\n","train_losses_div = []\n","train_losses_cos = []\n","eval_losses = []\n","\n","for epoch in range(num_epochs):\n","    model3.train()\n","    teacher_model.eval()\n","    train_loss = 0\n","    train_loss_cls = 0\n","    train_loss_div = 0\n","    train_loss_cos = 0\n","\n","    for batch in train_dataloader:\n","        batch = {k: v.to(device) for k, v in batch.items()}\n","        # compute student output\n","        outputs = model3(**batch)\n","        # compute teacher output\n","        with torch.no_grad():\n","            output_teacher = teacher_model(**batch)\n","\n","        # assert size\n","        assert outputs.logits.size() == output_teacher.logits.size()\n","\n","        # cls loss\n","        loss_cls  = outputs.loss\n","        train_loss_cls += loss_cls.item()\n","        # distillation loss\n","        loss_div = criterion_div(outputs.logits, output_teacher.logits)\n","        train_loss_div += loss_div.item()\n","        # cosine loss\n","        loss_cos = criterion_cos(output_teacher.logits, outputs.logits, torch.ones(output_teacher.logits.size()[0]).to(device))\n","        train_loss_cos += loss_cos.item()\n","\n","        # Average the loss and return it\n","        loss = (loss_cls + loss_div + loss_cos) / 3\n","\n","        train_loss += loss.item()\n","        loss.backward()\n","        # accelerator.backward(loss)\n","        # Step with optimizer\n","        optimizer3.step()\n","        lr_scheduler3.step()\n","        optimizer3.zero_grad()\n","        progress_bar.update(1)\n","\n","    train_losses.append(train_loss / len(train_dataloader))\n","    train_losses_cls.append(train_loss_cls / len(train_dataloader))\n","    train_losses_div.append(train_loss_div / len(train_dataloader))\n","    train_losses_cos.append(train_loss_cos / len(train_dataloader))\n","\n","    print(f'Epoch at {epoch+1}: Train loss {train_loss/len(train_dataloader):.4f}:')\n","    print(f'  - Loss_cls: {train_loss_cls/len(train_dataloader):.4f}')\n","    print(f'  - Loss_div: {train_loss_div/len(train_dataloader):.4f}')\n","    print(f'  - Loss_cos: {train_loss_cos/len(train_dataloader):.4f}')\n","\n","    model3.eval()\n","    eval_loss = 0\n","    for batch in eval_dataloader:\n","        batch = {k: v.to(device) for k, v in batch.items()}\n","        with torch.no_grad():\n","            outputs = model3(**batch)\n","\n","        loss_cls = outputs.loss\n","        predictions = outputs.logits.argmax(dim=-1)\n","\n","        eval_loss += loss_cls.item()\n","        # predictions, references = accelerator.gather((predictions, batch[\"labels\"]))\n","        metric.add_batch(\n","            predictions=predictions,\n","            references=batch[\"labels\"])\n","\n","    eval_metric = metric.compute()\n","    eval_metrics += eval_metric['accuracy']\n","    eval_losses.append(eval_loss / len(eval_dataloader))  # Save the evaluation loss for plotting\n","\n","    print(f\"Epoch at {epoch+1}: Test Acc {eval_metric['accuracy']:.4f}\")\n","\n","print('Avg Metric', eval_metrics/num_epochs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":500,"referenced_widgets":["76d2bc53d9914549b3c6dae7c70d6c88","a6f3eb3093e44bbb9dd65727ed84f784","bcd6b2d88a3d4597a602b3beda2812f4","bb84e790f4834fa6981472de7871898d","18c3baa486a14d6d8cc4552785cc2b31","11879c8c2f8e49479d48bd007410495e","856a3d529a824162b544ec069bb6c0d9","0dd5490a66d049e0b23d2d82e05226f0","19e4af8193d34404a94e4cef90d05006","66c000007eea448183abe91b58543d38","d6f87e27daa240a991139f9563d237bf"]},"id":"18e38K-YEIlg","executionInfo":{"status":"ok","timestamp":1710236937714,"user_tz":-420,"elapsed":235364,"user":{"displayName":"Pirunrat Kaewphanoaw","userId":"16190790272292098917"}},"outputId":"0fc4d7d4-6e0c-4ed0-e275-fe1b96dd86aa"},"execution_count":58,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/10 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"76d2bc53d9914549b3c6dae7c70d6c88"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch at 1: Train loss 0.3134:\n","  - Loss_cls: 0.8408\n","  - Loss_div: 0.0443\n","  - Loss_cos: 0.0551\n","Epoch at 1: Test Acc 0.2000\n","Epoch at 2: Train loss 0.2912:\n","  - Loss_cls: 0.7852\n","  - Loss_div: 0.0435\n","  - Loss_cos: 0.0449\n","Epoch at 2: Test Acc 0.2000\n","Epoch at 3: Train loss 0.2831:\n","  - Loss_cls: 0.7298\n","  - Loss_div: 0.0622\n","  - Loss_cos: 0.0575\n","Epoch at 3: Test Acc 0.2000\n","Epoch at 4: Train loss 0.2722:\n","  - Loss_cls: 0.6743\n","  - Loss_div: 0.0808\n","  - Loss_cos: 0.0617\n","Epoch at 4: Test Acc 0.3000\n","Epoch at 5: Train loss 0.2706:\n","  - Loss_cls: 0.6436\n","  - Loss_div: 0.0966\n","  - Loss_cos: 0.0718\n","Epoch at 5: Test Acc 0.3000\n","Avg Metric 0.24000000000000005\n"]}]},{"cell_type":"markdown","source":["4.Even"],"metadata":{"id":"HLhgIOpUGhUQ"}},{"cell_type":"code","source":["import torch\n","from tqdm.auto import tqdm\n","\n","progress_bar = tqdm(range(num_training_steps))\n","eval_metrics = 0\n","\n","# Lists to store losses for each epoch\n","train_losses = []\n","train_losses_cls = []\n","train_losses_div = []\n","train_losses_cos = []\n","eval_losses = []\n","\n","for epoch in range(num_epochs):\n","    model4.train()\n","    teacher_model.eval()\n","    train_loss = 0\n","    train_loss_cls = 0\n","    train_loss_div = 0\n","    train_loss_cos = 0\n","\n","    for batch in train_dataloader:\n","        batch = {k: v.to(device) for k, v in batch.items()}\n","        # compute student output\n","        outputs = model4(**batch)\n","        # compute teacher output\n","        with torch.no_grad():\n","            output_teacher = teacher_model(**batch)\n","\n","        # assert size\n","        assert outputs.logits.size() == output_teacher.logits.size()\n","\n","        # cls loss\n","        loss_cls  = outputs.loss\n","        train_loss_cls += loss_cls.item()\n","        # distillation loss\n","        loss_div = criterion_div(outputs.logits, output_teacher.logits)\n","        train_loss_div += loss_div.item()\n","        # cosine loss\n","        loss_cos = criterion_cos(output_teacher.logits, outputs.logits, torch.ones(output_teacher.logits.size()[0]).to(device))\n","        train_loss_cos += loss_cos.item()\n","\n","        # Average the loss and return it\n","        loss = (loss_cls + loss_div + loss_cos) / 3\n","\n","        train_loss += loss.item()\n","        loss.backward()\n","        # accelerator.backward(loss)\n","        # Step with optimizer\n","        optimizer4.step()\n","        lr_scheduler4.step()\n","        optimizer4.zero_grad()\n","        progress_bar.update(1)\n","\n","    train_losses.append(train_loss / len(train_dataloader))\n","    train_losses_cls.append(train_loss_cls / len(train_dataloader))\n","    train_losses_div.append(train_loss_div / len(train_dataloader))\n","    train_losses_cos.append(train_loss_cos / len(train_dataloader))\n","\n","    print(f'Epoch at {epoch+1}: Train loss {train_loss/len(train_dataloader):.4f}:')\n","    print(f'  - Loss_cls: {train_loss_cls/len(train_dataloader):.4f}')\n","    print(f'  - Loss_div: {train_loss_div/len(train_dataloader):.4f}')\n","    print(f'  - Loss_cos: {train_loss_cos/len(train_dataloader):.4f}')\n","\n","    model4.eval()\n","    eval_loss = 0\n","    for batch in eval_dataloader:\n","        batch = {k: v.to(device) for k, v in batch.items()}\n","        with torch.no_grad():\n","            outputs = model4(**batch)\n","\n","        loss_cls = outputs.loss\n","        predictions = outputs.logits.argmax(dim=-1)\n","\n","        eval_loss += loss_cls.item()\n","        # predictions, references = accelerator.gather((predictions, batch[\"labels\"]))\n","        metric.add_batch(\n","            predictions=predictions,\n","            references=batch[\"labels\"])\n","\n","    eval_metric = metric.compute()\n","    eval_metrics += eval_metric['accuracy']\n","    eval_losses.append(eval_loss / len(eval_dataloader))  # Save the evaluation loss for plotting\n","\n","    print(f\"Epoch at {epoch+1}: Test Acc {eval_metric['accuracy']:.4f}\")\n","\n","print('Avg Metric', eval_metrics/num_epochs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":500,"referenced_widgets":["a16368a75e2040e79d89527df28b4bdf","5884a12f59cf4747af3cf1cbec14b10e","ce80d3ed939f44a4b9aef0e658e68964","f082d9f74e5240aa914257fa9a5981ab","13450969c4024e3c86111d9c161e4cca","f841c16a533b40e291543191e94946eb","d4c5c63773384cd2a39ad36cced891df","c9b84448bf964ea0b2b6848abcffb556","8e55f2de41d84b75bd27c239c5ae95df","5e828b89af1d4025aecd641ae4f6ad13","4fa03ffc43c84afbb54dbb512fc56c85"]},"id":"QRizbIqyGjjw","executionInfo":{"status":"ok","timestamp":1710237190848,"user_tz":-420,"elapsed":253146,"user":{"displayName":"Pirunrat Kaewphanoaw","userId":"16190790272292098917"}},"outputId":"0558873e-712d-4fbe-9d60-1a20113e2b4b"},"execution_count":59,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/10 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a16368a75e2040e79d89527df28b4bdf"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch at 1: Train loss 0.2704:\n","  - Loss_cls: 0.6576\n","  - Loss_div: 0.0872\n","  - Loss_cos: 0.0662\n","Epoch at 1: Test Acc 0.2000\n","Epoch at 2: Train loss 0.2618:\n","  - Loss_cls: 0.6086\n","  - Loss_div: 0.1106\n","  - Loss_cos: 0.0663\n","Epoch at 2: Test Acc 0.3000\n","Epoch at 3: Train loss 0.2602:\n","  - Loss_cls: 0.5702\n","  - Loss_div: 0.1349\n","  - Loss_cos: 0.0756\n","Epoch at 3: Test Acc 0.3000\n","Epoch at 4: Train loss 0.2523:\n","  - Loss_cls: 0.5410\n","  - Loss_div: 0.1448\n","  - Loss_cos: 0.0713\n","Epoch at 4: Test Acc 0.2000\n","Epoch at 5: Train loss 0.2500:\n","  - Loss_cls: 0.5463\n","  - Loss_div: 0.1375\n","  - Loss_cos: 0.0662\n","Epoch at 5: Test Acc 0.2000\n","Avg Metric 0.24\n"]}]},{"cell_type":"markdown","source":["**Results and Discussion**"],"metadata":{"id":"8OKGMynuZrxs"}},{"cell_type":"code","source":["import pandas as pd\n","\n","# Calculate average values\n","train_loss_avg = (0.4423 + 0.4256 + 0.4140 + 0.4094) / 4\n","val_loss_avg = (0.4000 + 0.3000 + 0.3000 + 0.5000) / 4\n","val_acc_avg = (0.4 + 0.3 + 0.3 + 0.5) / 4\n","\n","# Create DataFrame\n","data = {\n","    \"Category\": [\"Top k\", \"Bottom k\", \"Odd\", \"Even\"],\n","    \"Train Loss\": [0.4423, 0.4256, 0.4140, 0.4094],\n","    \"Validation Loss\": [0.4000, 0.3000, 0.3000, 0.5000],\n","    \"Validation Accuracy\": [0.4, 0.3, 0.3, 0.5]\n","}\n","\n","# Add average values to the DataFrame\n","data[\"Train Loss\"].append(train_loss_avg)\n","data[\"Validation Loss\"].append(val_loss_avg)\n","data[\"Validation Accuracy\"].append(val_acc_avg)\n","data[\"Category\"].append(\"Average\")\n","\n","# Create DataFrame\n","df = pd.DataFrame(data)\n","df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"0t2A-H-8ZxJk","executionInfo":{"status":"ok","timestamp":1710237590982,"user_tz":-420,"elapsed":315,"user":{"displayName":"Pirunrat Kaewphanoaw","userId":"16190790272292098917"}},"outputId":"2ce2807d-7e46-401a-da8a-8ca0753baedc"},"execution_count":60,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   Category  Train Loss  Validation Loss  Validation Accuracy\n","0     Top k    0.442300            0.400                0.400\n","1  Bottom k    0.425600            0.300                0.300\n","2       Odd    0.414000            0.300                0.300\n","3      Even    0.409400            0.500                0.500\n","4   Average    0.422825            0.375                0.375"],"text/html":["\n","  <div id=\"df-8c646b63-7bc0-4609-a5e3-07f16545f040\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Category</th>\n","      <th>Train Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Validation Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Top k</td>\n","      <td>0.442300</td>\n","      <td>0.400</td>\n","      <td>0.400</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Bottom k</td>\n","      <td>0.425600</td>\n","      <td>0.300</td>\n","      <td>0.300</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Odd</td>\n","      <td>0.414000</td>\n","      <td>0.300</td>\n","      <td>0.300</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Even</td>\n","      <td>0.409400</td>\n","      <td>0.500</td>\n","      <td>0.500</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Average</td>\n","      <td>0.422825</td>\n","      <td>0.375</td>\n","      <td>0.375</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8c646b63-7bc0-4609-a5e3-07f16545f040')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-8c646b63-7bc0-4609-a5e3-07f16545f040 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-8c646b63-7bc0-4609-a5e3-07f16545f040');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-5679cfcb-7c22-42ba-8899-9cd7fa7c1fa2\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5679cfcb-7c22-42ba-8899-9cd7fa7c1fa2')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-5679cfcb-7c22-42ba-8899-9cd7fa7c1fa2 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df","summary":"{\n  \"name\": \"df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Category\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Bottom k\",\n          \"Average\",\n          \"Odd\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Train Loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.01269928639727447,\n        \"min\": 0.4094,\n        \"max\": 0.4423,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.4256,\n          0.422825,\n          0.414\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Validation Loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.082915619758885,\n        \"min\": 0.3,\n        \"max\": 0.5,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.3,\n          0.375,\n          0.4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Validation Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.082915619758885,\n        \"min\": 0.3,\n        \"max\": 0.5,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.3,\n          0.375,\n          0.4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":60}]},{"cell_type":"markdown","source":["- Train Loss:\n","\n","The average train loss across all categories is approximately 0.4228. This indicates the overall performance of the model during training.\n","\n","- Validation Loss:\n","\n","The average validation loss is approximately 0.375, which is lower than the average train loss. This suggests that the model may be slightly overfitting during training.\n","\n","- Validation Accuracy:\n","\n","The average validation accuracy is 0.375. This metric indicates the overall performance of the model on unseen data.\n","\n","- Category Analysis:\n","\n","Top k: This category has the highest average train loss (0.4423) and the highest validation loss (0.4000). The validation accuracy is 0.4.\n","Bottom k: This category has a slightly lower average train loss (0.4256) compared to the top k, and the validation loss is lower (0.3000). The validation accuracy is 0.3.\n","Odd: This category has a lower average train loss (0.4140) compared to the top k and bottom k, and the validation loss is 0.3. The validation accuracy is 0.3.\n","Even: This category has the lowest average train loss (0.4094), but it has the highest validation loss (0.5000) among all categories. The validation accuracy is the highest among all categories at 0.5.\n","\n","- Overall Analysis:\n","\n","The model seems to perform better on even epochs based on validation accuracy, although it has the highest validation loss.\n","There might be some overfitting issues as the validation loss is generally lower than the training loss, which could suggest that the model is memorizing the training data rather than learning generalizable patterns.\n","Further analysis and tuning may be required to improve the model's performance, such as regularization techniques or adjusting the model architecture."],"metadata":{"id":"M4BvUn5Gbj80"}},{"cell_type":"code","source":[],"metadata":{"id":"8FvlVA_9bwvI"},"execution_count":null,"outputs":[]}]}